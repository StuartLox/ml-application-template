#!/usr/bin/python3

import os
import sys
import time
import traceback

import numpy as np
import pandas as pd
import tensorflow as tf

from keras.layers import Dropout, Dense
from keras.wrappers.scikit_learn import KerasClassifier
from keras.models import Sequential

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import GridSearchCV

from cloudwatch import CWEvalMetrics

# Optional
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# These are the paths to where SageMaker mounts interesting things in your
# container.
prefix = '/opt/ml/'

input_path = prefix + 'input/data/'
output_path = os.path.join(prefix, 'output')
model_path = os.path.join(prefix, 'model')

# This algorithm has a single channel of input data called 'training'.
# Since we run in File mode, the input files are copied to the directory
# specified here.
channel_name = 'training'
training_path = os.path.join(input_path, channel_name)

def set_dataframe():
    input_files = [ os.path.join(training_path, file) for file in os.listdir(training_path) ]
    if len(input_files) == 0:
        raise ValueError(("There are no files in {}.\n"
                          "This usually indicates that the channel ({}) was incorrectly specified"
                          "the data specification in S3 was incorrectly specified or the role specified\n"
                          "does not have permission to access the data.").format(training_path, channel_name))
    raw_data = [ pd.read_csv(file, header=None) for file in input_files ]
    return pd.concat(raw_data)


def data_process(dataset):
    dataset.iloc[:,6] = (dataset.iloc[:,6]
                    .replace('?', dataset[dataset.iloc[:,6] !='?']
                    .iloc[:, 6].median()).astype('float64')
                   )
    # Set features and class variables.
    dataset = dataset.values
    X = dataset[:, 1:-1]
    y = dataset[:, -1]

    # One hot encode class variable.
    encoder = LabelEncoder()
    dummy_y = encoder.fit_transform(y)

    # # Feature Scaling
    # sc = StandardScaler()
    # X = sc.fit_transform(X)

    return X, y


# Building the ANN
def build_model(optimizer):
    # Initialize ANN
    model = Sequential()

    # First hidden layer with 10% dropout
    model.add(Dense(
        activation="relu",
        input_dim=9,
        units=8,
        kernel_initializer="uniform"))
    model.add(Dropout(rate=0.1))

    # The second hidden layer with 10% dropout
    model.add(Dense(
        activation="relu",
        units=8,
        kernel_initializer="uniform"))
    model.add(Dropout(rate=0.1))

    # Adding the output layer
    model.add(Dense(
        activation="sigmoid",
        units=1,
        kernel_initializer="uniform"))

    # Compiling the ANN
    model.compile(
        optimizer=optimizer,
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    return model


def generate_model(X_train, y_train):
    # Build classifier using grid search
    model = KerasClassifier(build_fn=build_model)

    # Create a dict of hyperparameters to optimize
    parameters = {
        # Tune batch size, epoch, optimizer
        'batch_size': [25, 32],
        'nb_epoch': [100, 500],
        'optimizer': ['adam', 'rmsprop']
    }

    # Implement GridSearch
    grid_search = GridSearchCV(
        estimator=model,
        param_grid=parameters,
        scoring='accuracy',
        cv=2
    )

    # Fit gridsearch to training set
    optimized_classifier = grid_search.fit(
        X_train,
        y_train
    )
    
    return optimized_classifier

def model_metrics(grid_result):
    region = 'ap-southeast-2'
    model_name = 'ANN-BreastCancer'
    CWMetrics = CWEvalMetrics(region=region, model_name=model_name)
    hyperparameters = {'batch_size': 25, 'epochs': 100, 'learning_rate': 0.1,'momentum': 0.9,'log_interval': 100, 'optimizer': 'adam'}
    for i, mean_test in enumerate(grid_result.cv_results_['mean_test_score']):
        CWMetrics.CW_eval(model_name,
                          AccuracyTest=mean_test*100, 
                          AccuracyTrain=grid_result.cv_results_['mean_train_score'][i]*100, 
                          hyperparameters=hyperparameters)
        time.sleep(5)
    CWMetrics.create_dashboard("ANN-Dash-2", hyperparameters=hyperparameters)

    def train():
        print('Starting the training.')
        try:
            raw_data = set_dataframe()
            X, y = data_process(raw_data)
            print(X)
            optimized_classifier = generate_model(X, y)
            # model_metrics(optimized_classifier)
            optimized_classifier.best_estimator_.model.save(
                os.path.join(model_path, 'ann-churn.h5'))
            print('Training is complete.')
        except Exception as e:
            # Write out an error file. This will be returned as the failure
            # Reason in the DescribeTrainingJob result.
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during training: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs
        print(
            'Exception during training: ' + str(e) + '\n' + trc,
            file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)


if __name__ == '__main__':
    train()

    # A zero exit code causes the job to be marked a Succeeded.
    sys.exit(0)